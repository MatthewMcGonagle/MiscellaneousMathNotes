Here we record some general notes on analysis.

\subsection{Different Types of Scalings and Convergence of Limits} \label{sub:limits}

Consider a function \(f(x,y) : \mathbb R^2 \to \mathbb R^2\). To determine if the limit \(\lim\limits_{\vec x\to\vec0} f(x,y)\) exists, it is NOT enough to consider the limit of the function along any line approaching \(\vec 0\). To construct such a counter example, it is convenient to consider a function that is homogeneous for parabolic scalings \((x,y) \to (\lambda x, \lambda^2 y)\). In particular we want the function to remain constant under such parabolic scalings.

To construct such a function, start with an ordinary homogeneous function \(g(u,v)\) and set \(f(x,y) = g(x^2, y)\). We immediately try
\[
	g(u,v) = \frac{uv}{u^2 + v^2}.
\]
So,
\[
	f(x,y) = \frac{x^2 y}{x^4 + y^2}.
\]
We see that \(f(x,y)\) has the desired properties. In particular, along any line through the origin, the function approaches \(0\). However, along the parabola \(y = mx^2\), we have that \(f(x,y) = m/(1+m^2),\) which is non-constant in \(m\).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Compact Operators}

Consider the Fredholm Alternative (for reference consult Gilbarg-Trudinger).

\begin{theorem}
	Let \(T: V \to V\) be a compact operator and let \(S = I - T\). Then either
	\begin{itemize}
		\item The kernel of \(S\) is trivial and \(S\) is also onto. Furthermore, the inverse \(S^{-1}\) is continuous.
		\item The kernel of \(S\) is non-trivial.
	\end{itemize}

\end{theorem}

Note that the Fredholm Alternative tells us that operators \(S\) that differ from the identity \(I\) by a compact operator \(T\) act like linear transformations on finite dimensional vector spaces. Furthermore, the use of the identity \(I\) here is important, as can be seen in the following example.

\begin{example}
	Consider the Banach space \(V = l^p\) given by the space of sequences with finite norm \(\|a_n\| = \left(\sum_n |a_n|^p\right)^{1/p}\). We have that the operator \(T: V \to V\) given by \(T(a_n)_m = 2^{-m} a_m\) is a compact operator. Furthermore, the kernel of \(T\) is trivial. However, \(T\) is not onto. The sequence \(y_n = 2^{-n}\) is not in the image of \(V\).

	However, note that the operator \(S = I - T\) is onto. For any sequence \(y_n \in l^p\), the sequence \(x_n = \left(1 - 2^{-n}\right)^{-1} y_n\) is also in \(l^p\). Furthermore, we get that the inverse of \(S\) is continuous.
\end{example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Regularity of Eigenvalues and Eigenvectors}\label{sub:eigen}

Consider a symmetric matrix function $M(x): \mathbb R^m \to \mathbb R^n\times \mathbb R^n$. At each point $x\in \mathbb R^m$, we have that the eigenvalues $\lambda_i$ of $M(x)$ are real valued. Therefore, we may uniquely indentify them using an ordering $\lambda_1 \leq ... \leq \lambda_m$. In general, if $M$ is smooth (or even analytic) each $\lambda_i$ may be only Lipschitz.

The Lipschitz nature of each $\lambda_i$ may be demonstrated by identifying each $\lambda_i$ with an inf-sup variational problem. In particular we have that
\begin{equation}
\lambda_i = \inf\limits_{\dim V = i} \sup\limits_{v\in V, \, \|v\| = 1} \langle v, Mv\rangle,
\end{equation}
where $V$ is an $i$-dimensional sub-space of $\mathbb R^n$.

Although the eigenvlaues are at least Lipschitz, there is no guarantee of the regularity of the eigenvectors, not even continuity. Problems occur when eigenvalues have multiplicty greater than one.

Consider the matrix function
\begin{equation}
M(t) = \begin{pmatrix}
a(t) & b(t)\\
b(t) & c(t)
\end{pmatrix}.
\end{equation}
We see that the eigenfunctions are solutions to $\lambda^2 - (a + c)\lambda + ac-b^2 = 0$. Therefore,
\begin{align}
\lambda_i & = \frac{a+c \pm \sqrt{(a+c)^2 - 4(ac - b^2)}}{2},\\
& = \frac{a+c \pm \sqrt{(a-c)^2 + 4 b^2}}{2}
\end{align}

We see that $\lambda_i$ are continuous and their derivatives don't exist only when $(a-c)^2 + 4b^2 = 0.$ For the case of $M(t)$ smooth, when this occurs we actually have that $(a-c)^2 + 4b^2 = \mathcal O((t-t_0)^2).$ So, we see that $\lambda_i$ will be Lipschitz.

\begin{example}
Consider the explicit example

\begin{equation}
M(t) = \begin{pmatrix}
1 + t & t\\
t & 1-t
\end{pmatrix}.
\end{equation}

Then, we have that
\begin{equation}
\lambda_i = 1 \pm \sqrt{2}|t|.
\end{equation}

For $\lambda_1 = 1-\sqrt{2}|t|,$ we see that the choices of normalized eigenvector are
\begin{equation}
v = \frac{\pm 1}{\sqrt{t^2 + (t+\sqrt{2}|t|)^2}}\begin{pmatrix} -t \\ t+\sqrt{2}|t|  \end{pmatrix}.
\end{equation}

So then we have the one sided limit
\begin{equation}\label{analysis:eq_8}
\lim\limits_{t\to 0+} v = \frac{\pm 1}{\sqrt{1+(1+\sqrt{2})^2}}\begin{pmatrix}-1 \\ 1 + \sqrt{2} \end{pmatrix},
\end{equation}
and the other one sided limit is
\begin{equation}\label{analysis:eq_9}
\lim\limits_{t\to 0-} v = \frac{\mp 1}{\sqrt{1+(1-\sqrt{2})^2}}\begin{pmatrix}-1 \\ 1 - \sqrt{2} \end{pmatrix}.
\end{equation}

We see that there is no choice of $\pm 1$ in equation \eqref{analysis:eq_8} and no choice of $\pm 1$ in equation \eqref{analysis:eq_9} that will make $v$ continuous at $t=0$. Therefore any choice of normalized eigenvector must have a discontinuity at $t=0$.
\end{example}

The only regularity of the eigenvalues $\lambda_i$ that we are guaranteed is Lipschitz; however, symmetric functions $f$ of the eigenvalues have the same regularity as $f$ and the matrix $M(t)$.

 \begin{proposition}
 
Let $M(t) \in C^\infty$ be a $n\times n$ symmetric matrix function, and let $f: \mathbb R^n \to \mathbb R$ be a symmetric and smooth function. Then $g(t) = f(\lambda_1(t),..., \lambda_n(t))$ is smooth.

\end{proposition}

\begin{proof}

Consider any fixed time $t_0$. Let $x_0 = (\lambda_1(t_0), ..., \lambda_n(t_0)).$ Since $f$ is a symmetric function, we have that the Nth Taylor Expansion of $f$ around $x_0$ is of the form:
\begin{equation}
f(x_0 + h) = \sum\limits_{i=0}^N + \mathcal O( |h|^{N+1}),
\end{equation}
where $p_i(x)$ is a symmetric homogeneous polynomial of degree $i$. 

\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Regularity of Systems of ODE}
 
 Here we consider how the regularity results for systems of ODE are somewhat surprising. As we discussed in subsection \ref{sub::eigen}, smooth (and even analytic) matrix functions \(M(t)\) have in general at most Lipschitz regularity in their eigenvalues, and their normalized eigenvectors don't need to be continuous.
 
 Now, for a linear system of ODE's such as 
 \begin{equation}
 \vec x' = M(t) \vec x,
 \end{equation}
 the solutions are given by \(\vec x(t) = \exp\left( \int_0^t M(s) \ds \right) \vec x_0\). From this expression, the regularity of the solutions is immediately clear from the analycity of \(\exp\). However, for the moment forget this fact. Without the use of the \(\exp\) function, we may be inclined to solve this system by diagonalizing \(M(t)\) for each \(t\), and then attempt to derive equations for the coordinates in this time dependent eigenbasis.

Let us consider the case where the normalized eigenvectors are constant on \(\{t>0\}\), constant on \(\{t<0\}\), and have a discontinuity at \(t=0\). For example, we could consider
 \begin{equation}
 M(t) = \begin{pmatrix}1 & 0\\0 & 1 \end{pmatrix} + \phi(t) \begin{pmatrix}1 & 2 \\ 2 & 1 \end{pmatrix} + \psi(t) \begin{pmatrix} 0 & 1\\ 1 & 0 \end{pmatrix},
 \end{equation}
where \( \suppt \phi \subset [0,1]\) and \(\suppt \psi \subset [-1,0]\). For such a situation we get unlinked ODE for the eigen coordinates of \(\vec x\), and furthermore these are regular on \(\mathbb R\) (the equations for the coefficients extends smoothly across \(t=0\)). However, the discontinuity of the normalized eigenvectors should give us pause as to whether these solutions combined to give a regular \(\vec x(t)\) at \(t=0\).

From this analysis, the regularity isn't particular clear. Luckily, the closed form solution \(u(t) =  \exp\left( \int_0^t M(s) \ds \right) \vec x_0\) proves the regularity to us very readily. Compare this to the situation of linear elliptic equations with non-constant coefficients, e.g.
\begin{equation}
\begin{cases}
a_{ij}(x)  \partial^2_{ij}u = 0 & x \in\Omega\\
u (x) = \phi(x) & x \in\partial \Omega.
\end{cases}
\end{equation}
Here a closed form solution isn't readily available to give us regularity. That must be done using more advanced methods.
Until the regularity is proven, it isn't clear that it should even be the case.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Inverse Function Theorem}

We will prove a weaker version of the inverse function theorem using differential equations. Consider $f: U \to V$. Let us consider the construction of the inverse of $f$ along a curve $\gamma(t) \in V$ with $\gamma(0) = 0$. We wish to construct a curve $\chi(t)$ with $\chi(0) = 0$ and $f\circ \chi (t) = \gamma(t)$. Differentiating, we see that $\chi(t)$ must necessarily satisfy $Df(\chi(t))\chi'(t) = \gamma'(t)$. Therefore, 
\begin{equation}\label{eq:analysis_1}
\chi'(t) = Df^{-1}(\chi(t)) \gamma'(t).
\end{equation}

By choosing a family of curves $\gamma(t)$ exhausting a neighborhood of $y=0$, we may construct $f^{-1}$ from \eqref{eq:analysis_1}.

\begin{proposition}
Let $U, V \subset \mathbb R^n$ be open, and let $0\in U, V$. Let $f: U \to V$ be such that $f\in C^1(U)$, $f(0) = 0$, $Df$ is invertible at every point of $U$, $Df^{-1}$ is Lipschitz on $U$.

Then there exists neighborhoods $0\in U' \subset U$ and $0\in V' \subset V$ such that $f$ is a bijection of $U'$ and $V'$. Furthermore, $f^{-1}$ is continuous on $V'$.
\end{proposition}

\begin{proof}
Consider the family of curves $\gamma_y(t) = ty$. Then $\gamma'(t) = y$. So, from \eqref{eq:analysis_1}, we seek to solve
\begin{equation}
\chi_y'(t) = Df^{-1}(\chi_y(t)) y.
\end{equation}

We reformulate this as a fixed point problem for an integral equation. For any function $\psi(y,t)$ we define the operator $T \psi(y,t) $ by
\begin{equation}
T \psi(y,t) = \int\limits_0^t Df^{-1}(\psi(y,s)) y \ds.
\end{equation}

Then, we seek to find $\chi(y,t)$ such that $T\chi(y,t) = \chi(y,t)$. Let $L$ be the Lipschitz constant of $Df^{-1}$ so that $|Df^{-1}(x_1) - Df^{-1}(x_2)| \leq L |x_1 - x_2|$. Then we see that
\begin{align}
|T\psi(y,t) - T\phi(y,t)| & \leq \int_0^t L|\psi(y,s) - \phi(y,s)| |y| \ds,\\
& \leq L  \| \psi - \phi\|_{C^0} |ty|.
\end{align}

So, for some neighborhood $V' \subset V$, letting $W = V'\times(-2, 2)$, we get that $T$ takes a convex neighborhood $N$ in $C^0(W)$ of $\psi(y,t) = 0$ to itself. Furthermore, 
\begin{equation}
\|T\psi - T\phi\|_{C^0(W)} \leq \frac{1}{2} \|\psi - \phi\|_{C^0(W)}.
\end{equation}
Therefore, by the contraction mapping principle there is a unique $\chi(y,t) \in N$ such that $T\chi = \chi$. Define $g(y) = \chi(y,1)$. So, by the definition of $\chi(y,t)$, we have that $f\circ g(y) = y$. Therefore, $g: V' \to U$ is injective.

Now, from the differentiability of $f$, we have that $f(x) = f(0) + Df(0)x + \mathcal O(\|x\|^2)$. Since $Df(0)$ is non-singular, we have $\|Df(0)x\| \geq \|Df^{-1}(0)\| \|x\|$. Hence, for some neighborhood $0\in U'\subset U$, we have that $f$ is injective on $U'$. Furthermore, we may take $U'$ such that $f: U' \to V'$. Hence, $f$ and $g$ give continuous bijections between $U'$ and $V'$.
\end{proof}

Now we extend the regularity.

\begin{proposition}
If $f: U \to V$ is a continuous homeomorphism, $f\in C^1(U)$, and $Df$ non-singular in $U$. Then, $f^{-1}\in C^1(V)$.
\textcolor{red}{PROOF IS INCORRECT OR INCOMPLETE. DISREGARD PROPOSITION FOR NOW.}
\end{proposition}

\begin{proof}
\textcolor{red}{THIS PROOF IS INCORRECT/INCOMPLETE}.
Let $y = f(x)$ and let us consider restricting $h$ such that $\|Df(x+h)-Df(x)\|<(1/2)\|Df(x)\|$. We have that 
\begin{align}
f(x+h) - f(x) & = \int_0^1 Df(x+ th) \dt h,\\
&  = \int_0^1 \left(Df(x+h) - Df(x)\right)\dt h + Df(x)h.
\end{align}

Now, $\left\|\int_0^1 \left(Df(x+h) - Df(x)\right)\dt\right\| \leq (1/2) \|Df(x)\|$.

We use the first order approximation of $f$. Since differentiability is local information, we may assume without loss in generality that $1/C \leq \|Df\| \leq C$ on $U$. Now, we have that for any $x_1, x_2 \in U$ that $f(x_2) = f(x_1) + Df(x_1) (x_2 - x_1) + \mathcal O(\|x_2 - x_1\|^2)$. Let $y_1 = f(x_1)$ and $y_2 = f(x_2)$. Then we have $y_2 = y_1 + Df(f^{-1}(y_1)) (f$

At any point $y\in V$ and any direction $w$ consider the curve $\gamma(t) = y + tw \in V$. Let $f(x) = y$ and consider the direction $v$ such that $Df(x)v = w$. Let $\chi(t) = x + tv \in U$.

From the differentiabilty of $f\circ \chi(t)$, we have that $f\circ \chi(t)  = y + wt + \mathcal O(t^2).$ Therefore, we get that $g(y+tw) - g(y) = g(f\circ\chi(t) + \mathcal O(t^2)) - x$.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Weak Derivatives}

Let us motivate the Sobolev notion of weak derivative. For weak derivatives in the Sobolev sense, the weak derivative captures how the function changes in the average. Let us first examine the integration by parts formula for weak derivatives:

\begin{equation}
a
\end{equation}
