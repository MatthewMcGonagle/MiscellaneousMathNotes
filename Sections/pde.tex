Here we record some general notes on PDE.

\subsection{Weak Solutions}

Let us motivate the use of weak solutions. Let $D = \{\|x\| = 1\|\subset \mathbb R^2$ be the unit disk in $\mathbb R^2$. Let us consider the case of harmonic functions solving the dirichlet problem on the unit disk $D\subset\mathbb R^2$, 
\begin{equation}
\begin{cases}
\laplace u = 0 & x\in D, \\
u = \phi & x\in \partial D.
\end{cases}
\end{equation}

Let us define the energy of $u$ by
\begin{equation}
E(u) = \int_D |\grad u|^2 \dA.
\end{equation}
Now, for $u \in C^2(D)\cap C(\bar D)$ and for $\phi\in C^2(D)\cap C(\bar D)$ with $\phi = 0$ on $\partial D$ one can show that $E(u+\phi) \geq E(u)$, with equality only if $\phi = 0.$ That is, $u$ must be a strict minimizer of $E(u)$ for functions $\{ w \in C^2(D) \cap C(\bar D) | w = \phi \text{ on } \partial D\}$.

However, now note that the energy $E(u)$ is still well-defined for $V = \{u\in C^2(D\setminus\{0\})\cap C(\bar D \setminus \{0\}) : E(u) < \infty\}.$ So, we may ask ouselves to search for minimizers in the space of functions $V$. After all, why should nature be restricted to continuous functions?

For example, the potential function $u(x,y) = \log r$ is harmonic on $D\setminus\{0\}$ and continuous up to the boundary of the disk. Although $E(u) = \infty$ and $u\not\in V$, it does add to the motivation to consider the possibility of harmonic functions with singularities. The function $u$ has a singularity at $(x,y) = 0$. We in fact have that $\laplace u = C \delta(x,y)$ as distributions, and so in some sense it is not true that $u = \log r$ is harmonic on $D\setminus \{0\}$. However, for now, let us just consider solutions in the classical sense of derivatives.

Let us first consider the standard example of $u$ bounded and harmonic on $D\setminus\{0\}$.

\begin{proposition}
Let $u \in C^2(D\setminus\{0\})\cap C(\bar D\setminus \{0\})$ be bounded and harmonic in $D\setminus\{0\}$. Then, $u$ is harmonic in $D$, and so $u\in C^\infty(D)$.
\end{proposition}

\begin{proof}
Consider the function $v$ solving the dirichlet problem
\begin{equation}
\begin{cases}
\laplace v = 0 & x \in D,\\
v = u & x\in \partial D.
\end{cases}
\end{equation}
By considering $u - v$, without loss in generality, we may suppose $u = 0$ on $\partial D$.

Let $|u|\leq M$ on $D\setminus\{0\}$. Let $w_\delta^+$ be the solution to the Dirichlet problem
\begin{equation}
\begin{cases}
\laplace w_\delta^+ = 0 & x \in D\setminus D_\delta(0),\\
w_\delta^+ = 0 & x\in \partial D,\\
w_\delta^+ = M & x\in \partial D_\delta(0).
\end{cases}
\end{equation}
A computation gives
\begin{equation}
w_\delta^+ = M\frac{\log r}{\log\delta}.
\end{equation}

Similary, for the boundary condition $w_\delta^- = -M$ on $\partial D_\delta(0)$, consider the function
\begin{equation}
w_\delta^- = -M\frac{\log r}{\log\delta}.
\end{equation}

By the maximum principle for harmonic functions, we have that $w_\delta^- \leq u \leq w_\delta^+$ on $D \setminus D_\delta(0)$. So, for some fixed $0<\delta_0<1$, we get that $|u| \leq M \log\delta_0 / -\log\delta$ on $D\setminus D_\delta(0)$. This is true as $\delta\to 0$, and so we get that $u=0$ on $D\setminus 0$. Therefore, $u$ is trivially harmonic on $D$.
\end{proof}

\begin{proposition}
Let $u \in C^2(D\setminus\{0\})\cap C(\bar D\setminus \{0\})$ be $\mathcal O (|\log r|^\alpha)$ for $0<\alpha<1$ and harmonic in $D\setminus\{0\}$. Then, $u$ is harmonic in $D$, and so $u\in C^\infty(D)$.
\end{proposition}

\begin{proof}
The proof is similar except we now use
\begin{equation}
w_\delta^\pm = \pm K(-\log\delta)^\alpha \frac{\log r}{\log \delta}.
\end{equation}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Estimates}

Estimates can be used for showing existence of solutions (see the use of Schauder Estimates and the Continuity Method to prove the existence of solutions to elliptic pde), and they may also be used to show control over how our solutions depend on the coefficients in our equations.

\begin{example}
Consider the boundary value problem
\begin{equation}
\begin{cases}
y'' - y = f_\epsilon(x) & 0<x<1,\\
y(0) = 0,\\
y(1) = 0,
\end{cases}
\end{equation}
where $f(x)$ is the piecewise function
\begin{equation}
f_\epsilon(x) = 
\begin{cases}
\frac{x}{\epsilon} & 0 \leq x < \epsilon,\\
2 - \frac{x}{\epsilon} & \epsilon \leq x < 2\epsilon,\\
0 & \text{otherwise}.
\end{cases}
\end{equation}

Now, note that $f_\epsilon \to 0$ in a pointwise manner, but $f_\epsilon \not \to 0$ in $C^0$. So, how much convergence do we need to ensure that the solutions $y \to 0$ as $\epsilon \to 0$? Let us consider this using the Laplace transform.

Now we consider finding a particular solution $y_p$, i.e. a solution to $y_p'' - y_p=0$ satisfying $y_p(0) = y_p'(0) = f_\epsilon$. Letting $Y_p(s) = \mathcal L y_p$ and $F_\epsilon(s) = \mathcal L f$, we see that $(s^2 - 1)Y_p = F_\epsilon.$ Therefore, we have that $Y_p = (s^2 - 1)^{-1} F_\epsilon$. So, we get that

\begin{equation}
y_p = \int\limits_0^x \sinh(x - \tau) f_\epsilon(\tau) \dtau.
\end{equation}
Therefore,
\begin{equation}
y = c_1 \cosh x + c_2 \sinh x + \int\limits_0^x \sinh(x-\tau)f_\epsilon(\tau) \dtau.
\end{equation}

Using the boundary conditions, we get that $c_1 = 0$ and
\begin{equation}
c_2 (\epsilon) = \frac{-1}{\sinh 1} \int\limits_0^1 \sinh(1-\tau)f_\epsilon(\tau)\dtau.
\end{equation}

Since $f_\epsilon \to 0$ in $L^1$, we see that the solutions $y\to 0$ in $C^0$. Furthermore,
\begin{equation}
y' = c_2(\epsilon)\cosh x  + \int\limits_0^x \cosh(x-\tau)f_\epsilon(\tau) \dtau.
\end{equation}
So, we see that $y \to 0$ in $C^1$ as $\epsilon \to 0$. However, note that $y \not \to 0$ in $C^2$. Note that this is to be expected from Schauder estimates since $f\not \to 0$ in $C^\alpha$ for any $0<\alpha<1$.

\end{example}

%%%%%%%%%%%%%%%%%

\begin{example}
Let us consider the related example of solving the boundary value problem

\begin{equation}
\begin{cases}
y'' - y = f_\epsilon(x) & 0 < x < 1,\\
y(0) = 0,\\
y(1) = 0,
\end{cases}
\end{equation}
where $f_\epsilon$ is the piecewise function
\begin{equation}
f(x) = \begin{cases}
\frac{x}{\epsilon^2} & 0 < x < \epsilon,\\
\frac{2}{\epsilon} - \frac{x}{\epsilon^2} & \epsilon< x< 2\epsilon,\\
0 & \text{otherwise}.
\end{cases}
\end{equation}
Note that $f \not \to 0$ in $L^1$.

Let us solve this in a piecewise manner. We see that
\begin{equation}
y = \begin{cases}
-\frac{x}{\epsilon^2} + c_1 \cosh x + c_2 \sinh x & 0<x<\epsilon,\\
\frac{x}{\epsilon^2} - \frac{2}{\epsilon} + c_3 \cosh x + c_4 \sinh x & \epsilon < x < 2\epsilon,\\
c_5 \cosh x + c_6 \sinh x & 2\epsilon < x < 1.
\end{cases}
\end{equation}

To solve for the constants $c_i$, we impose the two boundary conditions plus the four conditions from demanding that $y\in C^1$.Let
\begin{equation}
M = \begin{pmatrix}
1 & 0 & 0 & 0& 0 & 0\\
1 & 0 & -1 & 0 & 0 & 0\\
0 & 1 & 0 & -1 & 0 & 0\\
0 & 0 & 1 & 0 & -1 & 0\\
0 & 0 & 0 & 1 & 0 & -1\\
0 & 0 & 0 & 0 & \cosh 1 & \sinh 1
\end{pmatrix},
\end{equation}
and
\begin{equation}
N = 
\begin{pmatrix}
0 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & -1 & 0 & 0\\
1 & 0 & -1 & 0 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & -1 \\
0 & 0 & 1 & 0 & -1 & 0\\
0 & 0 & 0 & 0 & 0 & 0
\end{pmatrix}
\end{equation}
Then we have that our six conditions give that
\begin{equation}\label{pde:eq_28}
(M + \epsilon N + \mathcal O (\epsilon^2)) \vec c = \begin{pmatrix}
0\\
0\\
2/\epsilon^2\\
0\\
-1/\epsilon^2\\
0
\end{pmatrix}.
\end{equation}

Now, note that one can solve 
\begin{equation}
M \vec c_0 =  \begin{pmatrix}
0\\
0\\
2\\
0\\
-1\\
0
\end{pmatrix}
\end{equation}
rather directly (without even using row reduction) to get that
\begin{equation}
\vec c_0 = \begin{pmatrix}
0\\
1\\
0\\
-1\\
0\\
0
\end{pmatrix}.
\end{equation}

Therefore, we have that
\begin{equation}
(I + M^{-1}N \epsilon + \mathcal O(\epsilon^2))\vec c = \frac{1}{\epsilon^2}\vec c_0,
\end{equation}
and so
\begin{equation}
\vec c = \frac{1}{\epsilon^2}\vec c_0 -\frac{1}{\epsilon} M^{-1}N \vec c_0 + \mathcal O(1).
\end{equation}

Now, 
\begin{equation}
N \vec c_0 = \begin{pmatrix}
0\\
2\\
0\\
-1\\
0\\
0
\end{pmatrix}.
\end{equation}

Now we solve to get that
\begin{equation}
M^{-1} N \vec c_0 = 
\begin{pmatrix}
0\\
\cosh 1 /\sinh 1\\
-2\\
\cosh 1 / \sinh 1\\
-1 \\
\cosh 1 / \sinh 1
\end{pmatrix}
\end{equation}
So, we see that
\begin{equation}
y = \begin{cases}
-\frac{x}{\epsilon^2} + \frac{1}{\epsilon^2} \sinh x +\frac{1}{\epsilon}\frac{\cosh 1}{\sinh1} \sinh x + \mathcal O(1)& 0<x<\epsilon,\\
\frac{x}{\epsilon^2} - \frac{2}{\epsilon} - \frac{1}{\epsilon^2}\sinh x - \frac{2}{\epsilon} \cosh x +\frac{1}{\epsilon}\frac{\cosh 1}{\sinh1} \sinh x+ \mathcal O(1) & \epsilon < x < 2\epsilon,\\
-\frac{1}{\epsilon}\cosh x + \frac{1}{\epsilon}\frac{\cosh 1}{\sinh1} \sinh x + \mathcal O(1)& 2\epsilon < x < 1.
\end{cases}
\end{equation}

And we may simplify some of the order to get
\begin{equation}
y = \begin{cases}
\mathcal O(1)& 0<x<\epsilon,\\
- \frac{4}{\epsilon}  +\mathcal O(1) & \epsilon < x < 2\epsilon,\\
-\frac{1}{\epsilon}+ \mathcal O(1)& 2\epsilon < x < 1.
\end{cases}
\end{equation}

So we see that $y$ doesn't even converge to $0$ in a pointwise manner as $\epsilon \to 0$.
\end{example}